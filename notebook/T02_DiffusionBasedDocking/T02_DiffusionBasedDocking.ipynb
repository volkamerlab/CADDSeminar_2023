{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T002 · Diffusion-based docking models\n",
    "\n",
    "**Note:** This talktorial is a part of TeachOpenCADD, a platform that aims to teach domain-specific skills and to provide pipeline templates as starting points for research projects.\n",
    "\n",
    "Authors:\n",
    "\n",
    "- Hamza Ibrahim, CADD seminars 2023, Universität des Saarlandes (UdS)\n",
    "- Michael Bockenköhler, 2023,  [Volkamer lab](https://volkamerlab.org), Universität des Saarlandes (UdS)\n",
    "- Andrea Volkamer, 2023,  [Volkamer lab](https://volkamerlab.org), Universität des Saarlandes (UdS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim of this talktorial\n",
    "\n",
    "In this talktorial, we present two state-of-the-art classes of generative models. We start by defining generative models and explain the fundamentals of two powerful classes of generative models. Afterward, we will explore the implementation of one type of the presented generative models in the field of drug discovery and the challenges that were encountered and how they were solved."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents in *Theory*\n",
    "\n",
    "* Generative models\n",
    "    * Denoising diffusion probabilistic model (DDPM)\n",
    "        * Forward process\n",
    "        * Reverse process\n",
    "        * DDPM training\n",
    "            * Loss function\n",
    "            * Network architecture\n",
    "    * Score-based generative model\n",
    "        * Score model with stochastic differential equations (SDEs)\n",
    "* Diffusion-based docking models\n",
    "    * Ligand pose manifold\n",
    "    * Product space diffusion\n",
    "    * Model architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents in *Practical*\n",
    "\n",
    "* Data preparation\n",
    "    - Download PDB structure\n",
    "    - Prepare input data\n",
    "* DiffDock implementation\n",
    "* Denoising visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* Generative Modeling by Estimating Gradients of the Data Distribution: ([_arXiv_ (2019), 1907.05600](https://arxiv.org/abs/1907.05600))\n",
    "* Denoising Diffusion Probabilistic Models ([_arXiv_ (2020), 2006.11239](https://arxiv.org/abs/2006.11239))\n",
    "* Score-based generative modeling through stochastic differential equations: ([_arXiv_ (2021), 2011.13456](https://arxiv.org/abs/2011.13456))\n",
    "* DiffDock: Diffusion Steps, Twists, and Turns for Molecular Docking: ([_arXiv_ (2023), 2210.01776](https://arxiv.org/abs/2210.01776))\n",
    "* Equivariant Graph Neural Networks: ([_arXiv_ (2022), 2102.09844](https://arxiv.org/abs/2102.09844))\n",
    "* Deep Unsupervised Learning using Nonequilibrium Thermodynamics: ([_arXiv_ (2015), 1503.03585](https://arxiv.org/pdf/1503.03585.pdf))\n",
    "* [Diffusion Model Clearly Explained!](https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166)\n",
    "* [Generative Modeling by Estimating Gradients of the Data Distribution by Yang Song](https://yang-song.net/blog/2021/score/#connection-to-diffusion-models-and-others)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative models are a category of machine learning models that generate new data by learning the data distribution of a given training data set by injecting noise to the input. In a nutshell ***\"Creating noise from data is easy; creating data from noise is generative modeling.\"*** ([_arXiv_ (2021), 2011.13456](https://arxiv.org/abs/2011.13456)).\n",
    "\n",
    "In this section, we are going to discuss two advanced techniques used in generative modeling. The first type is the denoising diffusion probabilistic model (DDPM), which generates new data by _\"denoising\"_ the input data to predict the data distribution. The second type is score-based generative models. It utilzies the stochastic differential equations (SDEs) to reconstruct the data using **score function**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising diffusion probabilistic model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DDPM or so called \"diffusion model\" is inspired by Physics by non-equilibrium thermodynamics ([_arXiv_ (2015), 1503.03585](https://arxiv.org/pdf/1503.03585.pdf)). It learns to generate new data depending on two main reciprocal processes. These two main reciprocal processes are represented as two sets of random variables organized in the form of Markov process.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Forward diffusion process → add noise to input data.\n",
    "2. Reverse diffusion process → denoise noised data.\n",
    "<a id='fig1'></a>\n",
    "\n",
    "![DGM processes figure](images/basics_dgm.png)\n",
    "\n",
    "*Figure 1:* \n",
    "Black arrows represent the forward diffusion process, while blue arrow represents the reverse diffusion process.\n",
    "Figure is taken from: [Medium article](https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Forward process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first process adds gaussian noise sequentially to the input data $x_0$ by $T$ steps. After adding noise repeatedly, $x_T$ at some point becomes a complete static noise image as in [_figure 1_](#fig1). We can compute every successive state $\\mathbb{x}_{t + 1}$ as the following : "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "q(\\mathbb{x}_{t}|{x}_{t-1}) = \\mathcal{N(\\mathbb{x}_{t};\\mathbb{\\mu}_t = \\sqrt{1 - \\beta_t}{x}_{t-1}, \\Sigma_t = \\beta_t \\mathbf{I})}, \\tag{1}\n",
    "$$\n",
    "Where $q(\\mathbb{x}_{t}|{x}_{t-1})$ denotes the conditioned probability conditioned by $\\mathbb{x}_{t}$.\n",
    "\n",
    " $\\mathbb{\\mu}_t$ and $\\Sigma_t({x}_t, t)$ represent the mean and covariance of next state distribution, respectively."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Adding noise knowing it is normally distributed, enables us to compute the state at any given step. This can be done by utilizing the [reparametrization trick](https://medium.com/@steinsfu/diffusion-model-clearly-explained-cd331bd41166#228f). It prompts us to sample ${x}_{t}$ at any time step using ${x}_{0}$. It makes forward diffusion process much faster as following:\n",
    "$$\n",
    "{x}_{t} = \\sqrt{{\\bar{\\alpha}}_t} {x}_0 + \\sqrt{1 - {\\bar\\alpha}_t} {\\epsilon}_0, \\tag{2}\n",
    "$$\n",
    "\n",
    "Where ${\\bar\\alpha}_t = \\prod_{s = 0}^{t}{1 - {\\beta}_s}$ , and ${\\epsilon}_0, ... , {\\epsilon}_{t-2}, {\\epsilon}_{t-1} \\sim \\mathcal{N (0 , \\mathbf{I})}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Reverse process"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, It's not possible to sample ${x}_{0}$ from ${x}_{t}$ using $q(\\mathbb{x}_{t-1}|{x}_{t})$ like in the forward process, because reversing the noise is intractable, therefore **reverse diffusion process** is employed. As a solution $q(\\mathbb{x}_{t-1}|{x}_{t})$ could be approximated by using a deep learning model (e.g. neural network), which predicts an approximation to the conditional probability distribution $\\mathbb{p}_{\\theta}(\\mathbb{x}_{t-1}|{x}_{t})$, which modeled as a Gaussian distribution:\n",
    "\n",
    "$$\n",
    "\\mathbb{p}_{\\theta}(\\mathbb{x}_{t-1}|{x}_{t}) = \\mathcal{N(\\mathbb{x}_{t-1};\\mathbb{\\mu}_\\theta({x}_t, t), \\Sigma_t({x}_t, t))}, \\tag{3}\n",
    "$$\n",
    "\n",
    "By learning the conditional probability densities using a deep learning model the original image $x_0$ is reconstructed from the noisy image $\\mathbb{x}_t$ as illustrated in _figure 1_. Allowing for the extraction of meaningful information from the noisy representation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After explaining the two main processes of diffusion models, we start now with training the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a diffusion model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of training a diffusion model is to recostructed given noised data by predicting the original data distribution. \n",
    "\n",
    "To effectively train a generative model, It's necessary to define an optimized loss function and the architecture of the deep learning model. In this section we will explain briefly the loss function and the network architecture, which is commonly employed in diffusion models then we'll explain the training process of diffusion models.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diffusion model has some similarities with variational autoencoders [(VAEs)](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73). They are both generative models used to learn data distribution to generate new data. Maximizing the log-likelihood as a loss function guides the model towards better prediction accuracy.\n",
    "\n",
    "$$\n",
    "\\underset{\\theta}{\\text{max}}\\sum_{i=1}^{N}\\log{p_\\theta(x_i)} \\tag{4}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In diffusion models the log-likelihood is intractable. However, we can indirectly optimize it by optimizing the [lower variational bound](https://en.wikipedia.org/wiki/Evidence_lower_bound). By skipping mathimatical details, [Ho et al.(2020)](https://arxiv.org/pdf/2006.11239.pdf) has simplified the loss function to:\n",
    "$$\n",
    "{L}_{t}^{simple} = \\mathbb{E}_{t ,x_0, \\epsilon}[|| \\epsilon - {\\epsilon}_\\theta(x_t,t)||^2] \\tag{5}\n",
    "$$ \n",
    "where: \n",
    "\n",
    "$\\epsilon \\sim \\mathcal{N}(0, \\mathbb{I})$ is the actual noise added, which follows a standard normal distribution.\n",
    "\n",
    "${\\epsilon}_\\theta(x_t,t) = {\\epsilon}_\\theta(\\sqrt{\\bar\\alpha} x_0 + \\sqrt{1 - \\bar\\alpha} \\epsilon,t) $ denotes the approximated noise from a neural network using reparametrization trick that mentioned before.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is the difference between predicted and true values. As demonstrated, the simplified loss function is the mean square error (MSE) of the added noise and predicted noise.\n",
    "\n",
    "In the context of diffusion models the true value corresponds to the distribution of added noise that is introduced to an image and the model's objective is to learn the original data distribution from the \"noisy\" version of the input data.\n",
    "\n",
    "Once the loss function has been chosen, we can go to the next step, which is selecting an appropriate network architecture and training the diffusion model.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Network architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important requirement of the network is to have identical dimensionality for the input and the output. Therefore, usually, [U-Net](https://theaisummer.com/unet-architectures/) is commonly used for prediction tasks in diffusion models as a network architecture, more information can be found in the [appendix](#appendix)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By optimizing the gradient descent of the loss function, the model can be trained until it converges."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we got a clear idea of the outline of DDPM. In the next section, we'll explain another type of generative models, which is score-based generative model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score-based generative model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose a given data set {$x_1, ..., x_{N-1}, x_N$} which follows a certain probability distribution, denoted as $p(x)$. The primary goal of the score model is fitting a model to the given distribution $p(x)$ so that new data points can be generated by sampling from the learned distribution.\n",
    "\n",
    "However, first, we need to think of a good way that represents the probability distribution well. One way is to model the probability density function (PDF) directly. So, let $f_\\theta(x) \\isin \\mathbb{R}$ parameterized by $\\theta$, which is learnable parameter. PDF of a probabilistic model $f_\\theta(x)$ is defined as follow : \n",
    "\n",
    "$$\n",
    "p_\\theta(x)= \\frac{e^{-f_\\theta(x)}}{\\mathbb{Z_\\theta}}, \\tag{6}\n",
    "$$\n",
    "\n",
    "As $\\mathbb{Z_\\theta} > 0$ is the normalizing constant, depends on $\\theta$. The model can be trained by maximizing the log-likelihood of the PDF as in equation (4).\n",
    "\n",
    "However, a general normalizing constant $\\mathbb{Z_0}$ is most of the time intractable and we can't compute $p_\\theta(x)$. To overcome the intractability problem of $\\mathbb{Z_0}$, **score function** is modeled instead of the PDF, which is defined as :\n",
    "\n",
    "$$\n",
    "s_\\theta(x) = \\nabla_x \\log {p(x)} \\tag{7}\n",
    "$$\n",
    "\n",
    "$s_\\theta(x)$ is a score-based model and can be parametrized without the need to evaluate $\\mathbb{Z_0}$. By taking the gradient of the distribution, the normalizing constant becomes zero and we can ignore it as in equation 8.\n",
    "\n",
    "$$\n",
    "s_\\theta(x) = - \\nabla_x f_\\theta(x) - \\nabla_x \\log{\\mathbb{Z_0}} =  - \\nabla_x f_\\theta(x) \\tag{8}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown [_figure 2_](#fig2), there is no need to use normalization while parameterizing score functions. On the contrary, changes in data distribution undergo normalization, as the integration of area under the curve (AUC) must be one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig2'></a>\n",
    "\n",
    "<p float=\"left\">\n",
    "  <img src=\"images/ebm.gif\" height=\"280\" width=\"400\" />\n",
    "  <img src=\"images/score.gif\" height=\"280\" width=\"400\" /> \n",
    "</p>\n",
    "\n",
    "*Figure 2:* \n",
    "Parameterization of probability density functions (on the left) and score functions (on right). \n",
    "Figures are taken from: [Yang-Song blogpost](https://yang-song.net/blog/2021/score/#connection-to-diffusion-models-and-others)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Score model with stochastic differential equations (SDEs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding multiple noise scale at different scales has shown an improvement to the model's ability to generate high quality samples. By increasing the noise scale to infinity, exact log-likelihood can be also obtained. By injecting noise to the data, the concept becomes similar to DDPM. However, the main difference in this scenario is that the noise perturbation is a continous-time [stochastic process](https://en.wikipedia.org/wiki/Stochastic_process#:~:text=A%20stochastic%20process%20is%20defined,measurable%20with%20respect%20to%20some) as shown in [figure 3](#fig3)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig3'></a>\n",
    "\n",
    "<img src=\"images/sde_schematic.jpg\" height=400 width =1000  style=\"margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "*Figure 3:* \n",
    "An overview of a forward and reverse SDE in general.\n",
    "Figure is taken from: ([_arXiv_ (2021), 2011.13456](https://arxiv.org/abs/2011.13456))."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like DDPM we get now the forward process and reverse process of SDE. Keep in mind that using SDE is not a unique approach and there are different ways to add noise perturbations, one way is shown in the example. However, the score function is used to generate data in the reverse SDE, as demonstrated in [_figure 3_](#fig3). which will use score matching for training the score-based model. For more comprehensive understanding, you can find more detailed information about training a score-based generative model in the appendix, [score model training](#scoremodel) section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, two main state-of-the-art generative models are well-covered. In the next section, we discuss a novel tool called _DiffDock_. It has employed a generative model to tackle the challenge of molecular docking in the field of cheminformatics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diffusion-based docking model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main concepts of creating a generative model are explained. It's important to note that implementing the generative model in molecular docking will not be the same as we explained. In this section, we discuss the challenges encountered in applying the generative model, especially the score-based generative model, in molecular docking and how these obstacles have been overcome in a real-case application."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Ligand pose manifold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have a diffusion-based docking model, you have to think of a manifold that suits ligand poses first where $L \\isin \\mathbb{R}^{3n} $ as $n$ is the number of atoms. If we start forward diffusing without setting any limitations for the degree of freedom, it becomes absurd and ligands will have unreasonable bond lengths and angles as in [_figure 4_](#fig4)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig4'></a>\n",
    "\n",
    "<img src=\"images/absurd_ligand.png\"  style=\"margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "*Figure 4:* \n",
    "Randomizing bond length and angles without keeping local structures fixed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A solution to this problem is presented in [DiffDock paper](https://arxiv.org/pdf/2210.01776v2.pdf). They are inspired by traditional docking approaches by taking already embedded ligands in a 3D space using RDKit, which instantiates the angles and bond length of the atoms. Instead of thinking of a ligand as an element in euclidean space, they described ligand pose by four main parameters. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Local structures like bond lengths, bond angles, chirality, and ring structure are generated using RDKit and kept fixed in order to maintain the integrity of the predicted ligand and the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Position of the ligand with the 3D translation group was left flexible to find the pocket and fit in it $\\mathbb{R}^3$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Rotation parameterization, where $Rotation \\in {SO(3)}$ corresponds to 3D rigid rotation around the mass center of the ligand.\n",
    "\n",
    "<img src=\"images/rotation.gif\"  style=\"width:300px;\">\n",
    "\n",
    "\n",
    "*Figure 5:* \n",
    "GIF shows an example of the rotation of a methyl group in an Ethane structure. Figure is taken from [Proteopedia](https://proteopedia.org/wiki/index.php/Dihedral/Index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Flexibility of torsion angles to fit in the pocket, where: $ \\mathit{Torsions} \\in \\mathbb{T}^m$, which represent the changes in torsion angles around rotatable bonds in a ligand with a 2D rotation group ${SO(2)}$ copy.  \n",
    "\n",
    "### Change GIF \n",
    "<img src=\"images/Phipsi-AH.gif\"  style=\"width:400px;\">\n",
    "\n",
    "*Figure 6:* \n",
    "GIF illustrates the torsion angles and changes in them. As shown a torsion angle ϕ is defined by four covalently bonded atoms. Every three atoms defines a half-plane and when these planes intersect the angle between them is the torsion angle ϕ. Figure is taken from [Proteopedia](https://proteopedia.org/wiki/index.php/Dihedral/Index)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These four parameters have introduced a new challenge. The problem arises from the fact that there are several valid possibilities for making changes through rotations and alterations in torsion angles together. The used strategy in DiffDock is to _disentangle_ the degrees of freedom involved in docking, which aims to isolate the modification of torsion angles from other transformations such as rotation and translations.\n",
    "\n",
    "To make sure that the changes in torsion were independent during docking, post-torsion RMSD alignment was performed to confirm that rotations and translations were orthogonal to torsion modifications."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By utilizing those parameters, it was possible to map ligand poses into submanifold $\\mathcal{M}_c \\subset \\mathbb{R}^{3n}$, where they can easily define the diffusion process. This submanifold $\\mathcal{M}_c$ facilitates diffusion over a space where ligand poses are represented in $(m + 6)$ dimensions, where $m$ denotes the count of rotatable bonds.\n",
    "\n",
    "Fortunately, the ligand pose submanifold establishes a smooth mapping to the product space. As a result, we can now map displacements within the manifold of ligand poses to the product space. This product space, denoted as : $\\mathbb{P} = \\mathbb{R}^3 * {SO(3)} * \\mathbb{T}^m$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Product space diffusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After mapping the ligand pose manifold to the product space, a score-based generative model with SDE is trained with **score matching** according to [Song et al. 2019](https://arxiv.org/abs/1907.05600) to compute the score of the diffusion kernel on the product space and sample from it. But here appears another problem which is how the score model will be diffused on the product space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that most of the existing score-based generative models are designed for data on an euclidean space. However, [De Bortoli et al. 2022](https://arxiv.org/pdf/2202.02763.pdf) has developed a Riemannian score-based generative model (SGM) which is based on Riemannian manifold and gives the possibility to create SGMs of various manifolds.\n",
    "\n",
    "The main concept is to consider the score model not as a vector field on the euclidean space, but rather as a vector field on the manifold where the score and the score model are components within the tangent space of every possible point on the manifold as represented in [_figure 7_](#fig7). \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig7'></a>\n",
    "\n",
    "<img src=\"images/tangent_space.png\"  style=\"width:400px;\">\n",
    "\n",
    "*Figure 7:* The tangent space, denoted as ${T_xM}$ represents the set of all possible tangent vectors $v$ at $x$ as $x \\isin \\mathcal{M}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before product space is the product of three manifolds. So, in order to proceed with the forward diffusion process on the product space, every manifold will be diffused independently according to [Rodol`a et al., 2019](https://arxiv.org/abs/1809.10940) and the tangent space will be computed as the sum of every manifold:\n",
    "\n",
    "$$\n",
    "T_g \\mathbb{P} = T_r\\mathbb{T^3} \\oplus T_RSO(3) \\oplus T_\\theta SO(2)^m \n",
    "$$\n",
    "Therefore, we can sample from diffusion kernel and conduct independet regression analysis against the true score within each group."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Model architecture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence model and the score model are constructed using [E(3)NN](https://arxiv.org/abs/2207.09453). For more information on E(3)NN, you can refer to [__Talktorial T036__](https://projects.volkamerlab.org/teachopencadd/talktorials/T036_e3_equivariant_gnn.html).\n",
    "\n",
    "A score-based generative model is used to simulate the reverse diffusion starting from the \"noisy\" version of the ligand-protein interaction using reverse SDE to denoising and find the right binding pocket.\n",
    "\n",
    "While the confidence model is responsible for ranking the arbitrarily generated number of ligands. It's trained as a classifier especially to rank the poses and find the best-generated conformers as demonstrated in [_figure 8_](#fig8).\n",
    "\n",
    "Unlike other traditional docking tools, DiffDock doesn't predict the affinity of a ligand to a protein. It predicts a confidence score, which gives you a view of how good the ligand is. The higher the confidence score is, the better the quality of generated conformer and more likely to be a good ligand. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig8'></a>\n",
    "\n",
    "![DiffDock workflow](images/DiffDock.png)\n",
    "\n",
    "*Figure 8:* \n",
    "Overview of DiffDock workflow. Left: The model takes as input the separate ligand and protein\n",
    "structures. Center: Score-based generative model where random initial poses are denoised via a reverse SDE over translational, rotational, and torsional degrees of freedom. Right:. The sampled poses are ranked by the\n",
    "confidence model to produce a final prediction and confidence score.\n",
    "Figure and discription taken from: [arXiv 2023](https://arxiv.org/pdf/2210.01776v2.pdf)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiffDock has shown an significant improvement in comparison to tradition docking. It achieved a $38%%$% success rate in making predictions with RMSD below $2$, whereas the best traditional docking tool used got $28%$%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Data preparation.\n",
    "    - Download PDB structure\n",
    "    - Prepare input file\n",
    "* DiffDock implementation\n",
    "* Denoising visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the practical part we are going to implement _DiffDock_, which used in molecular docking trained using score-based generative model. It's now open-source and published on [Github](https://github.com/gcorso/DiffDock).\n",
    "\n",
    "It's highly recommended to create an environment using environment.yml file through [Anaconda](), in order to get the code excuted without bugs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from PIL import Image\n",
    "import urllib\n",
    "from pymol import cmd\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting _DiffDock_ implementation, input data has to be prepared. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare protein structure\n",
    "\n",
    "If you want to download the protein structure. Set `protein_pdb` to your PDB code of the structure you want to use. You can use your own protein, but you need to place it in `DATA` path and set `protein_pdb` to your protein pdb structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#By default, it's set to transcription inhibitor, PDB ID is `6moa`\n",
    "\n",
    "protein_id = '6moa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB structure with ID 6moa already downloaded.\n"
     ]
    }
   ],
   "source": [
    "# Download the PDB structure if it's not downloaded in `DATA` directory.\n",
    "\n",
    "if f'{protein_id}.pdb' not in os.listdir('data'):\n",
    "    urllib.request.urlretrieve(f'http://files.rcsb.org/download/{protein_id}.pdb', f'data/{protein_id}.pdb')\n",
    "else:\n",
    "    print(f'PDB structure with ID {protein_id} already downloaded.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's highly recommended to prepare your query protein structure before you start working on it. Many protein targets often have incomplete information such as missing hydrogen atoms, inaccurate protonation states, tautomers or the wrong position of hydrogen atoms of protein and the corresponding ligand. Ignoring the inaccurate information can have a high impact on the reliability of your docking results.\n",
    "\n",
    "An example of an open source tool that you can use to prepare your protein target is [Protoss](https://proteins.plus/help/protoss). It can be accessed through [Protein Plus server](https://proteins.plus/). you can upload your protein of interest and this tool can predict missing hydrogen atoms, determine reasonable protonation states and provide the right coordinates of hydrogen atoms in the binding pocket of the co-crystallized structure.\n",
    "\n",
    "For preparing the query protein, follow the next steps:\n",
    "1. Upload your query protein and follow instructions to use [Protoss tool](https://proteins.plus/help/protoss)\n",
    "2. Once the protein structure is prepared, download it and save it in `DATA` directory\n",
    "3. Rename the saved file by appending `_processed` to the `PDB ID`, as shown in next cell.\n",
    "4. If you followed all previous steps, excute the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change protein ID to the prepared protein structure\n",
    "\n",
    "if f\"{protein_id}_processed.pdb\" in os.listdir(DATA):\n",
    "    protein_id = \"6moa_processed\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify your query ligand\n",
    "\n",
    "In this step, you need to specify your ligand input. There are different input types can be used. SDF file or SMILES string. In case you want to use sdf file, change `ligand` variable to the path of SDF file.\n",
    "\n",
    "Unlike traditional docking tools, _DiffDock_ uses one quary per protein. Therefore, if you want to dock more than one ligand to the same protein, you can add it to `ligand_input` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ligand to ligand SMILES/SDF's path here\n",
    "ligand = [\"O=C(O)c1cc(/OCc2cccc3ccccc23)ccc1O\"]\n",
    "\n",
    "#Add molecule ID to this list\n",
    "molecule_id = ['Molecule_1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DiffDock implementation\n",
    "\n",
    "First step is to download _DiffDock_ software from its [Github repository](https://github.com/gcorso/DiffDock.git).\n",
    "In order to maintain stability of the environment file, we wil checkout for a specific version of the _DiffDock_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiffDock is alreay cloned.\n",
      "HEAD is now at 3d45728 fix inference_utils.py #90\n"
     ]
    }
   ],
   "source": [
    "if \"DiffDock\" not in os.listdir(HERE):\n",
    "    #specifiy version\n",
    "    !git clone https://github.com/gcorso/DiffDock\n",
    "else:\n",
    "    print(f\"DiffDock is alreay cloned.\")\n",
    "\n",
    "os.chdir(\"DiffDock\")\n",
    "!git checkout 3d45728415d2603dbceef5f6952817157f62d216\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure your docking settings\n",
    "\n",
    "It was found that it was the best configuration regarding a trade-off between the computational cost and accuracy of the results.\n",
    "\n",
    "- __ligands_per_complex__ is the number of predicted molecules for every complex.\n",
    "- __inference_steps__ is the number of denoising steps.\n",
    "- __actual_steps__ is the number of actual denoising steps that are performed.\n",
    "- __batch_size__ is the number of batches used. Reducing the number of batches decreases the computational resources required for execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The default setting to use DiffDock is as following\n",
    "\n",
    "ligands_per_complex = \"5\"\n",
    "inference_steps = \"20\"\n",
    "actual_steps = \"18\"\n",
    "batch_size = \"10\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first execution takes around 15 minutes, it precomputes the cache of $SO(3)$ and torus $\\mathbb{T}$ distribution table. It downloads automatically the checkpoints of the Evolutionary scale modeling (ESM) afterward which could take around 10 minutes, depending on your internet connection. \n",
    "\n",
    "ESM is used to predict the 3D protein structure, this can be utilized if your input is FASTA format and you want to predict the 3D protein structure as well. For further information, on how and why to use ESM, you can it on [ESM's repository](https://github.com/facebookresearch/esm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating ESM language model embeddings\n",
      "Processing 1 of 1 batches (1 sequences)\n",
      "HAPPENING | confidence model uses different type of graphs than the score model. Loading (or creating if not existing) the data for the confidence model now.\n",
      "Size of test dataset:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:40, 40.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed for 0 complexes\n",
      "Skipped 0 complexes\n",
      "Results are in /home/ibrahim/Github/CADDSeminar_2023/notebook/T02_DiffusionBasedDocking/data\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"DiffDock/\")\n",
    "for id, smiles in zip(molecule_id, ligand):\n",
    "    diffdock_cmd = f\"python -m inference --protein_path ../data/{protein_id}.pdb --ligand '{smiles}' --complex_name {protein_id} --out_dir {DATA} --inference_steps {inference_steps} --samples_per_complex {ligands_per_complex} --save_visualisation --batch_size {batch_size} --actual_steps {actual_steps} --no_final_step_noise\"\n",
    "    os.system(diffdock_cmd)\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising visualization\n",
    "In this step, we are going to visualize the denoising process of generated ligands within a Jupyter Notebook cell. Calling **--save_visualisation** argument, the model will save the inference steps of every ligand in one pdb file contains different coordinates of the ligand in results folder.\n",
    "\n",
    "In order to visualize the process here, we'll follow three main steps:\n",
    "\n",
    "- Split ligands in PDB file for every inference step to separate PDB files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ligands(pdb_path, rank):\n",
    "    '''''\n",
    "    \n",
    "    Separate ligands of every inference step in a pdb file to individual pdb files\n",
    "\n",
    "    @args: \n",
    "    pdb_path : .pdb file with multiple coordinates of a ligand for every inference step \n",
    "    \n",
    "    rank : the rank of the predicted molecules\n",
    "\n",
    "    @return:\n",
    "    individual pdb files for each ligand in `DATA/visualization` directory  \n",
    "\n",
    "    '''''\n",
    "    \n",
    "    #read pdb file\n",
    "    with open(pdb_path, \"r\") as pdb_file:\n",
    "        pdb_string = pdb_file.read()\n",
    "\n",
    "    #split ligand\n",
    "    pdb_models = pdb_string.strip().split(\"MODEL\")\n",
    "    model = 1\n",
    "\n",
    "    #write individual ligands\n",
    "    for pdb_model in pdb_models[1:]:\n",
    "\n",
    "        #create `visualization` directory\n",
    "        os.makedirs(DATA / protein_id / \"visualization\", exist_ok=True)\n",
    "\n",
    "        with open(f\"{str(DATA)}/{protein_id}/visualization/{model}.pdb\", \"w\") as pdb_output_file:\n",
    "            pdb_output_file.write(pdb_model)\n",
    "\n",
    "        model += 1\n",
    "    \n",
    "    print(f\"Rank {rank} ligand in different inference steps is now separated into individual PDB files.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Take screenshot of every ligand in every inference step with the query protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_screenshots(inference_steps, rank):\n",
    "    '''''\n",
    "    Load PDB file of a query protein and every ligand from the inference steps and create an image for every inference step.\n",
    "\n",
    "    @args:\n",
    "    ------\n",
    "    rank : the rank of the predicted molecules\n",
    "\n",
    "    inference_steps : Number of generated ligands for every denoising step\n",
    "\n",
    "    @return:\n",
    "    --------\n",
    "    create screenshots of a query protein, reference ligand, and the denoised ligands with multiple coordination \n",
    "    '''''\n",
    "    \n",
    "    for model in range(1, int(inference_steps)+2):\n",
    "\n",
    "        #load protein and reference ligand and set preferred preferences\n",
    "        cmd.load(f\"data/{protein_id}.pdb\", 'protein')\n",
    "        cmd.select('ligand', 'hetatm')\n",
    "        cmd.color('white', 'protein')\n",
    "        cmd.show('surface', 'protein')\n",
    "        cmd.hide('cartoon', 'protein')\n",
    "        cmd.set('transparency', 0.5,'protein')\n",
    "        cmd.color('green', 'ligand')\n",
    "\n",
    "        #load predicted ligands for every inference state\n",
    "        cmd.load(f\"{str(DATA)}/{protein_id}/visualization/{model}.pdb\", 'predicted_ligand')\n",
    "\n",
    "        #select ligand (Heteroatoms)\n",
    "        cmd.select('predicted_ligand')\n",
    "        \n",
    "        #change ligand color to yellow\n",
    "        cmd.color('yellow', 'predicted_ligand')\n",
    "\n",
    "        cmd.bg_color(\"white\")\n",
    "        cmd.orient('protein')\n",
    "        cmd.remove(\"solvent\") \n",
    "        # create a PNG image\n",
    "        cmd.png(f'{str(DATA)}/{protein_id}/visualization/image_{model}_{rank}.png', dpi=300)  \n",
    "        cmd.delete('all')\n",
    "\n",
    "        #clean directory from individual pdb files \n",
    "        os.remove(f\"{str(DATA)}/{protein_id}/visualization/{model}.pdb\")\n",
    "\n",
    "    print(f\"Screenshots are taken for rank {rank} ligand\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a graphics interchange format (GIF) for every generated ligand in different inference steps with the query protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif(inference_steps, rank):\n",
    "    '''''\n",
    "    create a graphics interchange format (GIF) for every generated ligand in different inference steps with the query protein\n",
    "\n",
    "    @args:\n",
    "    ------\n",
    "    rank : the rank of the predicted molecules\n",
    "\n",
    "    @return:\n",
    "    --------\n",
    "    GIF of denoising process of ligand-protein complex \n",
    "    '''''\n",
    "        \n",
    "    #create a list that contains all paths of ligand-protein screenshots\n",
    "    image_files = [f\"{str(DATA)}/{protein_id}/visualization/image_{i}_{rank}.png\" for i in range(1, int(inference_steps)+2)]\n",
    "    frames = [Image.open(image) for image in image_files]\n",
    "    \n",
    "    #save frames of the GIF as an endless loop.\n",
    "    frames[0].save(f\"{str(DATA)}/{protein_id}/visualization/reverse_diffusion_rank_{rank}.gif\", append_images=frames[1:],save_all=True, duration=100, disposal=2, loop=0)\n",
    "\n",
    "    #clean the folder from screenshots\n",
    "    [os.remove(image) for image in image_files]\n",
    "\n",
    "    print(f\"GIF of rank {rank} ligand is now ready!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the process of visualizing the ligands might require some time to excute, especially if it's more than three generated ligands due to the generation of high-quality screenshots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 ligand in different inference steps is now separated into individual PDB files.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m rank \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,\u001b[39mint\u001b[39m(ligands_per_complex)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m      6\u001b[0m     split_ligands(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mDATA\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mprotein_id\u001b[39m}\u001b[39;00m\u001b[39m/rank\u001b[39m\u001b[39m{\u001b[39;00mrank\u001b[39m}\u001b[39;00m\u001b[39m_reverseprocess.pdb\u001b[39m\u001b[39m\"\u001b[39m, rank)\n\u001b[0;32m----> 7\u001b[0m     create_screenshots(inference_steps, rank)\n\u001b[1;32m      8\u001b[0m     create_gif(inference_steps, rank)\n",
      "Cell \u001b[0;32mIn[17], line 40\u001b[0m, in \u001b[0;36mcreate_screenshots\u001b[0;34m(inference_steps, rank)\u001b[0m\n\u001b[1;32m     37\u001b[0m cmd\u001b[39m.\u001b[39morient(\u001b[39m'\u001b[39m\u001b[39mprotein\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39m# create a PNG image\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m cmd\u001b[39m.\u001b[39;49mpng(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mstr\u001b[39;49m(DATA)\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mprotein_id\u001b[39m}\u001b[39;49;00m\u001b[39m/visualization/image_\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mrank\u001b[39m}\u001b[39;49;00m\u001b[39m.png\u001b[39;49m\u001b[39m'\u001b[39;49m, dpi\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m)  \n\u001b[1;32m     41\u001b[0m cmd\u001b[39m.\u001b[39mdelete(\u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[39m#clean directory from individual pdb files \u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/diffdock/lib/python3.9/site-packages/pymol/exporting.py:614\u001b[0m, in \u001b[0;36mpng\u001b[0;34m(filename, width, height, dpi, ray, quiet, prior, format, _self)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[39mif\u001b[39;00m ray:\n\u001b[1;32m    612\u001b[0m     \u001b[39mreturn\u001b[39;00m func()\n\u001b[0;32m--> 614\u001b[0m \u001b[39mreturn\u001b[39;00m _self\u001b[39m.\u001b[39;49m_call_with_opengl_context(func)\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/diffdock/lib/python3.9/site-packages/pymol/cmd.py:164\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    162\u001b[0m _coordset_update_thread \u001b[39m=\u001b[39m internal\u001b[39m.\u001b[39m_coordset_update_thread\n\u001b[1;32m    163\u001b[0m _copy_image \u001b[39m=\u001b[39m internal\u001b[39m.\u001b[39m_copy_image\n\u001b[0;32m--> 164\u001b[0m _call_in_gui_thread \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m func: func()\n\u001b[1;32m    165\u001b[0m _call_with_opengl_context \u001b[39m=\u001b[39m _call_in_gui_thread\n\u001b[1;32m    166\u001b[0m _ctrl \u001b[39m=\u001b[39m internal\u001b[39m.\u001b[39m_ctrl\n",
      "File \u001b[0;32m~/mambaforge-pypy3/envs/diffdock/lib/python3.9/site-packages/pymol/exporting.py:596\u001b[0m, in \u001b[0;36mpng.<locals>.func\u001b[0;34m()\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m():\n\u001b[1;32m    595\u001b[0m     \u001b[39mwith\u001b[39;00m _self\u001b[39m.\u001b[39mlockcm:\n\u001b[0;32m--> 596\u001b[0m         \u001b[39mreturn\u001b[39;00m _cmd\u001b[39m.\u001b[39;49mpng(_self\u001b[39m.\u001b[39;49m_COb, filename, \u001b[39mint\u001b[39;49m(width), \u001b[39mint\u001b[39;49m(height),\n\u001b[1;32m    597\u001b[0m                         dpi, ray, \u001b[39mint\u001b[39;49m(quiet), prior, \u001b[39mformat\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if \"visualization\" not in os.listdir(DATA / protein_id ):\n",
    "\n",
    "    #pass if GIF is already created\n",
    "    for rank in range(1,int(ligands_per_complex)+1):\n",
    "        \n",
    "        split_ligands(f\"{DATA}/{protein_id}/rank{rank}_reverseprocess.pdb\", rank)\n",
    "        create_screenshots(inference_steps, rank)\n",
    "        create_gif(inference_steps, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"display:flex;\"><img src=\"/home/ibrahim/Github/CADDSeminar_2023/notebook/T02_DiffusionBasedDocking/data/6moa_processed/visualization/reverse_diffusion_rank_1.gif\" style=\"margin-right: 10px;\"><img src=\"/home/ibrahim/Github/CADDSeminar_2023/notebook/T02_DiffusionBasedDocking/data/6moa_processed/visualization/reverse_diffusion_rank_2.gif\" style=\"margin-right: 10px;\"><img src=\"/home/ibrahim/Github/CADDSeminar_2023/notebook/T02_DiffusionBasedDocking/data/6moa_processed/visualization/reverse_diffusion_rank_3.gif\" style=\"margin-right: 10px;\"><img src=\"/home/ibrahim/Github/CADDSeminar_2023/notebook/T02_DiffusionBasedDocking/data/6moa_processed/visualization/reverse_diffusion_rank_4.gif\" style=\"margin-right: 10px;\"><img src=\"/home/ibrahim/Github/CADDSeminar_2023/notebook/T02_DiffusionBasedDocking/data/6moa_processed/visualization/reverse_diffusion_rank_5.gif\" style=\"margin-right: 10px;\"></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gif_paths = [(f\"{str(DATA)}/{protein_id}/visualization/reverse_diffusion_rank_{rank}.gif\") for rank in range(1, int(ligands_per_complex)+1)]\n",
    "\n",
    "# Generate HTML code to display the GIFs side by side\n",
    "html_code = '<div style=\"display:flex;\">'\n",
    "for gif_path in gif_paths:\n",
    "    html_code += f'<img src=\"{gif_path}\" style=\"margin-right: 10px;\">'\n",
    "html_code += '</div>'\n",
    "\n",
    "# Display the HTML code\n",
    "display(HTML(html_code))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Throughout this talktorial, the fundamentals of two main types of generative models are explained, highlighting their powerful capability to generate new data by using minimal information as input. We've presented a case study in the field of cheminformatics, focusing on its application in molecular docking. However, there is still room for improvement in this field, primarily due to the distinct characteristics of chemical data and the challenges associated with it compared to other types of input data.\n",
    "\n",
    "In the presented case study _DiffDock_, the researchers had to find a way to introduce noise to the chemical data set. Which is a crucial step to implement a score-based generative model. Additionally, It was also challenging to identify a suitable manifold that can accommodate the noised chemical data, allowing for diffusion across its product space.\n",
    "\n",
    "_DiffDock_ demonstrated a significant improvement in docking power, with a 38% success rate. However, it's not without some limitations. Similar to many molecular docking literatures, it assumes that any given ligand-protein structure is a holo-structure (bound structure). Additionally, some protein structures have a cryptic binding site, which is not detected by _DiffDock_. Addressing these limitations and tackling them can increase the success rate of molecular docking approaches in future research."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "1. What is special about _DiffDock_ in comparison to tradtional docking methods? Would you considered these differences to be advantageous or disadvantageous? and why?\n",
    "2. What is the unit of the predicted _DiffDock_ output, and how does it compare to the outputs from traditional molecular docking tools, is it any better to get this output? and why?\n",
    "3. Why does DiffDock hold the assumption of ligand-protein structure as a holo-structure? How could it be overcome? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "<a id='appendix'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the supplementary section, we provide detailed explanations of important concepts that required for a comprehensive understanding of discussed topics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U-Net architecture based on an encoder-decoder structure. In encoding, the spatial dimensions decreases while the number of channels increases keeping the important features of the input data. On the contrary, in decoding the spatial dimensions increase while number of channels decrease to produce the same spatial dimensions as the input data as illustrated in [figure 9](#fig9)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig9'></a>\n",
    "\n",
    "<img src=\"images/Unet-architecture.png\"  style=\"margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "*Figure 9:* \n",
    "An overview of U-Net architecture.\n",
    "Figure is taken from: [AI Summer](https://theaisummer.com/static/fa507fda71846a516801bccb19474aec/0012b/Unet-architecture.png)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score model training \n",
    "<a id='scoremodel'></a>\n",
    "In order to train a score-based model, we need to compare between the model and the actual data distribution. This is done by minimizing a function that computes the distance between true score model and predicted score model like Fisher divergence, which defined as:\n",
    "\n",
    "$$\n",
    "\\mathbb{E_{p(x)}}[|| \\nabla_x \\log{p_{(x)}} - \\mathbb{s_\\theta(x)}||_2^2] \\tag{9}\n",
    "$$\n",
    "\n",
    "The ground-truth data score is unknown, which makes it infeasible to compute fisher divergence indirectly. However, **score matching** makes it feasible, because it can minimize fisher divergence without the estimation of the true data score and allow us to train the model.\n",
    "\n",
    "The model can be trained, but the main objective of the score-based model, which is generating new data, is not achieved. [Langevin dynamics](https://en.wikipedia.org/wiki/Langevin_dynamics) is used as a sampling method to generate new data, accessing only its score function as shown in [figure 10](#fig10).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='fig10'></a>\n",
    "<img src=\"images/smld.jpg\"  style=\"margin-left: auto; margin-right: auto;\">\n",
    "\n",
    "*Figure 10:* \n",
    "An overview of score-based generative modeling with score matching and langevin dynamics.\n",
    "Figure and description are taken from: [Yang-Song blogpost](https://yang-song.net/blog/2021/score/#connection-to-diffusion-models-and-others)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
