{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Thank you for contributing to TeachOpenCADD!</b>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Set up your PR</b>: Please check out our <a href=\"https://github.com/volkamerlab/teachopencadd/issues/41\">issue</a> on how to set up a PR for new talktorials, including standard checks and TODOs.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T04 Â· Predicting Drug Drug Interactions using SVM\n",
    "\n",
    "Authors:\n",
    "\n",
    "- Vanessa Siegel, 2023, CADD Seminar, Centre for Bioinformatics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim of this talktorial\n",
    "\n",
    "This talktorial introduces and explores the subject of drug-drug interactions (DDI) and their different types, paying special attention to the concepts of antagonism, additivity, and synergism. This will be followed by a closer look at Support Vector Machines (SVM) that use soft margin classifiers and then move towards a more detailed explanation on how to use a combined similarity matrix as a pairwise kernel function to solve the non-linear classification problem of predicting new DDI by comparing them to already known DDI.\n",
    "\n",
    "To build the combined similarity matrix, we will look at 2D and 3D structural similarity as well as similarity between interaction profiles and create databases for each of them. The dataset used during the practical part of this talktorial will be retrieved from [__DrugBank__](www.drugbank.ca) and filtered to only contain small molecule drugs that are annotated as approved for medical use in at least one country and for which 2D and 3D structural data is available.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents in *Theory*\n",
    "\n",
    "-\tDrug-Drug Interactions\n",
    "    - Importance of drug-drug interactions\n",
    "    - Drug-drug interaction types\n",
    "-\tDrug Similarity\n",
    "-\tSupport Vector Machines\n",
    "    - Soft Margin Classifer\n",
    "    - Kernel Trick\n",
    "-\tDrugBank\n",
    "    - History\n",
    "    - Drug Entries\n",
    "-\tWorkflow: Similarity-Based SVM for DDI Prediction\n",
    "    - Feature Selection\n",
    "    - Data Selection\n",
    "    - Creating drug-drug similarity databases\n",
    "    - Creating drug-pair similarity matrices\n",
    "    - Creating the pairwise kernel\n",
    "    - Modelling and evaluating the SVM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents in *Practical*\n",
    "\n",
    "-\tRetrieve data from DrugBank\n",
    "-\tCreate a drug-drug 2D molecular structure similarity database using RDkit\n",
    "-\tCreate a drug-drug 3D pharmacophoric similarity database using the E3FP and RDkit\n",
    "-\tCreate a drug-drug interaction profile database using RDkit\n",
    "-\tConstruct a combined pairwise similarity matrix for the kernel function\n",
    "-\tModel and evaluate the SVM\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "* Paper \n",
    "* Tutorial links\n",
    "* Other useful resources\n",
    "\n",
    "*We suggest the following citation style:*\n",
    "* Keyword describing resource: <i>Journal</i> (year), <b>volume</b>, pages (link to resource) \n",
    "\n",
    "*Example:*\n",
    "* ChEMBL web services: [<i>Nucleic Acids Res.</i> (2015), <b>43</b>, 612-620](https://academic.oup.com/nar/article/43/W1/W612/2467881) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Sync section titles with TOC</b>: Please make sure that all section titles in the <i>Theory</i> section are synced with the bullet point list provided in the <i>Aim of this talktorial</i> > <i>Contents in Theory</i> section.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug-Drug Interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance of drug-drug interactions\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clinical investigations and research in the biomedical field showed that to treat more complex diseases the administration of just one drug is often not enough. Diseases like HIV, cancer, or kidney failure, to name a few, often require a combination of drugs to achieve satisfactory results or improvements in the patients' health. However, the simultaneous use of multiple drugs often leads to the occurrence of drug-drug interactions (DDI).\n",
    "\n",
    "DDI are caused when one drug interfers with another in one or more stages of its lifetime circle in the body and through that influences the effectiveness of said drug. This means they either cause an unexpected medical effect or creates an unexpected but measurable difference of the two drugs in the patient's bloodstream. \n",
    "\n",
    "Notably, it does not matter if said influence or effect is beneficial or harmful to the biological system to be classified as a DDI. Thus, while DDI can be taken advantage of to increase a therapeutic effect, they are also a mayor cause for unwanted or unexpected adverse side effects in patients. Therefore, extensive knowledge about potential DDI is crucial in medical care.\n",
    "\n",
    "From ensuring that the patient doesn't take drugs which are known to negatively affect each other (e.g., causing adverse reactions, making one drug unusable, potentiating side effects to a severely harmful degree), over preventing existing medical conditions from worsening, up to taking advantage of synergistic DDI to give better treatment, knowledge of DDI has a wide field of applications. As such analysing new drugs or drug combinations for potential DDI is an important aspect in the advancement of personalized medicine.\n",
    "\n",
    "Since finding and verifying DDI is a costly process due to the amount of in vitro and in vivo experiments, computational means started to develop to filter the large number of potential drug combinations for those who show a high possibility for expressing DDI. Many of these computational methods use machine-learning techniques, such as the one discussed in this talktorial in more detail."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drug-drug interaction types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drug-drug interactions are commonly classified by the cause of their occurrence, meaning they are either caused by pharmacokinetic (PK) or pharmacodynamic (PD) interactions.\n",
    "\n",
    "__Pharmacokinetic DDI__ occur when drug A influences drug B's concentration in the blood stream. It does not matter if it is the active component of drug A or one of the additives, added to assist in the delivery of the drug, that is the cause of this interaction. \n",
    "PK DDI are separated into four categories depending on which stage of a drug's lifetime circle is affected: absorption, distribution, metabolism, or excretion (ADME).\n",
    "\n",
    "__Pharmacodynamic DDI__, on the other hand, occur when the pharmacological effect of drug A influences the pharmacological effect of drug B. This happens when A and B target similar or related biological pathways or targets. However, a PD DDI can also occur when the drugs affected pathways seem to be completely unrelated, but their pharmacological effects still cause an unexpected medical observation.\n",
    "\n",
    "PD DDI get classified into three groups: \n",
    "-\t__Antagonistic__: \n",
    "The combined effect caused by a drug combination is smaller than the sum of the pharmacological effects seen when each drug is given alone.\n",
    "-\t__Additive__:\n",
    "The combined effect caused by a drug combination is the sum of the pharmacological effects seen when each drug is given alone.\n",
    "-\t__Synergistic__:\n",
    "The combined effect caused by a drug combination is greater than the sum of the pharmacological effects seen when each drug is given alone.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Comparison Pharmacodynamic DDI Types](./images/PD%20DDI.jpg)\n",
    "\n",
    "*Figure 1:* Graphical representation of the three types of pharmacodynamic drug-drug interactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that a DDI can be of both types, signifying that this way of classification is to be seen more as a widely used guideline rather than hard-split categories. Similarly, the words antagonistic, additive, synergistic, and their synonyms are sometimes used to also categorize PK DDI, especially in the medical field where the distinction between PK and PD may not be of importance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "__IMPORTANT__:\n",
    "\n",
    "For the remainder of this talktorial, unless specified otherwise, DDI will not be differentiated into PK or PD. Likewise, the terms antagonistic, additive, and synergistic â if applied â will be used to describe all DDI as smaller, equal, and greater than the sum of their __therapeutic effect__ respectively as to not distract from the actual topic of this talktorial.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drug Similarity\n",
    "\n",
    "A base assumption in drug discovery is that similar drugs express similar properties and thus behave similar when introduced to a biological system. Computer-based methods use that assumption to cluster drugs or find molecules that have the potential to have an increased therapeutic effect to already known drugs. As such, it is important to clearly define how *similarity* is to be judged computationally.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining drug similarity to a computer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple different categories and properties that can be used to define similarity between different drugs, and machine learning algorithms often use a combination of them to make better predictions. This process is called feature selection and can have significant impact on the reliability of a model. But how does a computer compare two drugs?\n",
    "\n",
    "The most common way is to use fingerprints for the different properties and calculate similarity between them with the Tanimoto coefficient as described in Talktorial T004.\n",
    "\n",
    "For the Tanimoto coefficient we will use the following formula during this talktorial:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ TC(A,B) = |A \\cap B| / |A \\cup B| $"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown the formula divides the intersection of fingerprints A and B with the number of features present in the union of both fingerprints and calculates the *similarity* as a float value between 0 and 1 with 0 representing no similarity at all and 1 indicating the two drugs are *identical* in the given property."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Schematic example of 2D structural similarity calculation](./images/Fingerprint-based-molecular-similarity-approache-Modified.png)\n",
    "\n",
    "*Figure 2:*\n",
    "Example for the comparison between fingerprints of two molecules and the resulting Tanimoto coefficient. \n",
    "\n",
    "(Modified figure. Original taken from [*Molecular informatics.* (2021), __40__](https://www.researchgate.net/publication/351084895_Differential_Consistency_Analysis_Which_Similarity_Measures_can_be_Applied_in_Drug_Discovery))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D structural similarity\n",
    "For 2D structural similarity, we will create MACCS fingerprints and use the Tanimoto coefficient to calculate our 2D similarity score. A more detailed explanation of MACCS fingerprints can be found in [__Talktorial T004__](https://github.com/volkamerlab/teachopencadd/blob/master/teachopencadd/talktorials/T004_compound_similarity/talktorial.ipynb).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3D structural similarity\n",
    "\n",
    "For the calculation of the 3D structural similarity, we will use the \"Shape\" screening module which is part of the [__SchrÃ¶dinger 2011 package__](http://www.schrodinger.com). How this package calculates 3D similarity can be read up in the package's documentation and will not be discussed here.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interaction profile similarity\n",
    "\n",
    "Like 2D structural similarity, we will use the fingerprint method here as well and calculate the Tanimoto coefficient. For this, our vector will be the size of the number of drugs in our database, each position filled with a 1 if the drug has a known DDI with the drug corresponding to the respective cell and 0 otherwise.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines (SVM) are supervised learning models, used to analyse data for classification and regression purposes. Initially developed by Vladimir Vapnik and colleagues during the 1990s, SVMs became more and more popular as one of the most robust prediction methods in machine learning.\n",
    "\n",
    "Using a set of training examples and a binary label system, the SVM training algorithm maps each labelled training example to a point in space and then determines an optimal hyperplane to separate the two classes from each other. The hyperplane itself gets defined by a set of points from both classes, the so-called support vectors, and situated to maximize the margin, meaning the distance between itself and the chosen support vectors on both sides, to reliably separate the two classes.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SVM schema](./images/optimal-hyperplane.png)\n",
    "\n",
    "*Figure 3:* A schematic example of an optimal separating hyperplane.\n",
    "Figure was taken from [Open Source Computer Vision](https://docs.opencv.org/4.x/d1/d73/tutorial_introduction_to_svm.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft Margin Classifer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this talktorial, we will use a so-called __Soft Margin Classifier__, opposed to the stricter Hard Margin Classifier. This means that we allow both, outliers and potential misclassifications, in our training data when determining the position of the optimal separating hyperplane.\n",
    "\n",
    "That way, we guarantee that the positioning of the separating hyperplane is much more robust and less prone to overfit our training data, making the whole model more reliable when classifying new data points."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hard vs Soft Margin Classifier](./images/Hard-vs-Soft-Margin.jpg)\n",
    "\n",
    "*Figure 4:* A comparison between a Hard Margin Classifier (left) and a Soft Margin Classifier (right). Both optimal separating hyperplanes would be identical if the one blue outlier was not part of the data set. Figure was taken from [Mubaris NK](https://mubaris.com/posts/svm/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, to do so, the error parameter C which is used to punish the presence of outliers and misclassifications must be carefully chosen as to neither overfit our model nor to reduce specificity to the point that predictions will mean nothing. It is a very important step in handling the Bias/Variance Trade-off typical for machine learning models and unique to Soft Margin Classifiers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Effect of C](./images/Effect-of-soft-margin-constant-C-Modified.png)\n",
    "\n",
    "*Figure 5:* Comparison of different values for error parametre C and their impact on determining the optimal separating hyperplane.\n",
    "\n",
    "(Figure was modified. Original from [*PLoS computational biology.* (2008), __4__](https://www.researchgate.net/publication/23442384_Support_Vector_Machines_and_Kernels_for_Computational_Biology))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Trick"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notably the figures above all show examples of linear classification problems, meaning the two classes can be easily separated from each other with a linear hyperplane. However, this does not work when faced with a classification problem as depicted in the figure below. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CNon-linear Classification Problem](./images/nonlinear%20data.png)\n",
    "\n",
    "*Figure 6:* An example of a non-linear classification problem.\n",
    "Figure was taken from [Andrea Perlato](https://www.andreaperlato.com/theorypost/introduction-to-support-vector-machine/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For problems like this, SVMs have to make use of the __kernel trick__ to change a non-linear classification problem into a linear one before finding the optimal separating hyperplane.\n",
    "\n",
    "To do so, SVMs take the data points and artificially move them into a higher dimension with the help of a __kernel function__ which plots the data points in a manner to make them linearly separable. In this higher dimension, the SVM will then find an optimal separating hyperplane as described. In the last step, said hyperplane will get transformed back into the original dimension where it may no longer be linear.\n",
    "\n",
    "A simple example of how the kernel trick works is detailed in Figure 7, where we artificially plot the datapoints from a one-dimensional space into a two-dimensional space with a polynomial kernel function, determine the hyperplane, and then transform the data back into the original space."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Kernel Trick for Non-Linear Classification Problem](./images/Kernel%20trick.png)\n",
    "\n",
    "*Figure 7:* An example of the kernel trick on one-dimensional drug-dosage data. The chosen kernel function is a polynomial function of degree two: $f(x) = dosage^2$.\n",
    "Figure was taken from [Andrea Perlato](https://www.andreaperlato.com/theorypost/introduction-to-support-vector-machine/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the kernel function does not actually transform the data into a higher dimension and only calculates the relationships between every pair of points as if they were in the higher dimension, the whole method is called the kernel __trick__.\n",
    "\n",
    "As for the kernel function itself, there are many different ways of creating one. The kernel function introduced in this talktorial is a pairwise kernel method which uses a similarity matrix of drug pairs to perform the kernel trick. How exactly we calculate said function will be discussed in detail in the corresponding subsection of the *Workflow* chapter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DrugBank"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### History"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DrugBank is a comprehensive, free-to-access, online database containing information on drugs and drug targets. First established in 2006 by Dr David Wishart's lab at the University of Alberta as a project to grant academic researchers easier access to detailed, structured information about drugs, DrugBank grew in size and popularity thanks to the backing of various research organisations as well as government funding. Now in its 5th version (version 5.1.10 as of 1st April 2023), Drug Bank contains over 15,000 drug entries with almost 5,296 non-redundant protein sequences being linked to them. Each entry contains more than 200 data fields and combines detailed drug data (chemical, pharmacological, pharmaceutical, etc.) with comprehensive drug target data like sequence, structure, and pathway, collected from bioinformatics and cheminformatics resources."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drug Entries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each entry in the DrugBank database is clearly structured, systemically ordered, and possesses a unique number through which each drug can be clearly identified and addressed within the database. The toolbar to the left provides an easy way to navigate through the different categories and subcategories for which information for the drug at hand is provided, allowing for intuitive and easy access to the sought after information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot of DrugBank Entry Aspirin](./images/DrugBank%20Aspirin.png)\n",
    "\n",
    "*Figure 8:* \n",
    "Screenshot of the DrugBank Entry of [__Aspirin__](https://go.drugbank.com/drugs/DB00945). The red-framed toolbar provides easy access to different categories of drug information provided by DrugBank. The blue square marks the unique accession number through which each drug can be identified within the database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is to note that while categories for which no information is available might be removed from the navigation help, the presence of a certain field does not necessitate the presence of information. The example below nicely illustrates that while the category Pharmacology is present, for most of its subfields, information is not available."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot of DrugBank Entry 1,2-Benzodiazepin](./images/DrugBank%201%202-Benzodiazepine.png)\n",
    "\n",
    "*Figure 9:* \n",
    "Screenshot of the DrugBank Entry of [__1,2-Benzodiazepin__](https://go.drugbank.com/drugs/DB12537)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of this talktorial the only relevant information needed from these entries are:\n",
    "\n",
    "-\tThe __DrugBank Accession Number__\n",
    "-\tThe __Type__ of the drug (Small Molecule or Biotech)\n",
    "-\tWhich __Group(s)__ the drug belongs to\n",
    "-\tThe 2D structure in the __SMILE__ format\n",
    "-\tThe 3D structure in the __SDF file__ format\n",
    "-\tThe list of known __Drug Interactions__\n",
    "\n",
    "\n",
    "The DrugBank accession number will serve as an identification system during computations and consists out of the letters DB followed by a five-digit number.\n",
    "\n",
    "The Type and Group information is required to filter the database for only those drugs that qualify as small molecule drugs, and which were approved for use. \n",
    "\n",
    "The 2D and 3D structure information will be used to create fingerprints with RDkit and the SchrÃ¶dinger package respectively. \n",
    "\n",
    "Lastly the drug interactions will be used to create interaction profile fingerprints for each drug and also serve as the foundation for the assignment of labels to our training data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "__IMPORTANT__:\n",
    "\n",
    "It is to note that unlike the *Type*, the *Groups* are not an either-or classification system since DrugBank incorporates information from various countries and a drug that might be approved in one can still be illicit or experimental in another. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow: Similarity-Based SVM for DDI Prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection is a very big part of machine learning algorithms, especially when handling biological data where there are lots of features but only a limited amount of datapoints to use. How one chooses features depends on the availability of the data, the impact said feature might have on the problem at hand, and the computational effort to use it.\n",
    "\n",
    "As such, the first thing we need to do is decide which features we want to focus on. As previously mentioned, three different features were chosen for the sake of this tutorial: 2D structure, 3D structure, and drug interactions.\n",
    "\n",
    "2D structure is a commonly used feature in drug discovery since it allows for relatively easy first comparisons between drugs and proved reliable enough to build the basis for QSAR methods in pharmacy and drug Discovery. Moreover, a 2D molecular representation is generally available for drugs.\n",
    "\n",
    "The 3D structure was chosen to take into account that spatial orientation plays a very important role in all forms of protein-ligand interactions, and just like 2D structure, 3D structure is often available as well.\n",
    "\n",
    "Since drugs who already share a list of drugs which they interact with are much more likely to also interact with the drugs for which experimental data only exists for one of them, drug interactions were chosen as a feature that is both closely related to the purpose of the SVM we build and has to be sufficiently available for our future training dataset.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our features, it is time to collect our data. To predict DDI with a SVM, we require labelled datapoints for training with sufficiently enough examples for both classes to prevent too much bias towards one category.\n",
    "\n",
    "In our practical, we label drug pairs as having (1) or not having a DDI (0). For this example, neither the strength nor the type of DDI is of importance. If one wishes to pay more attention to a certain type of interaction, they need to adjust the labels accordingly.\n",
    "\n",
    "Downloading the DrugBank database version 5.1.10, we filter the database for all small molecule drugs that were approved for use in at least one country. In the next step we filter out all drugs for which DrugBank is unable to provide a SMILE string of the 2D structure or an SDF file for the 3D structure. If Drug Interactions are marked as 'Not Available' we will assume that these drugs do not show any noteworthy DDI.\n",
    "\n",
    "The list of drugs that remains will be our final dataset for the Practical."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating drug-drug similarity databases"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our dataset ready, it is now time to calculate similarity for each of the three features while looking at all possible drug combinations.\n",
    "\n",
    "To create the 2D structure similarity database we use RDkit (â¦) to transform the SMILE representation of each drug into a MACCS fingerprint. Once we have these, we calculate the Tanimoto Coefficient for all possible combinations of drugs and store these values in a similarity matrix for easy access.\n",
    "\n",
    "For the 3D structure similarity database, we use, as mentioned before, the E3FP package to create fingerprints directly from the 3D-SDF files. Those will then be transformed into fingerprints as they are used by RDkit, before we calculate a similarity score for each possible drug combination.\n",
    "\n",
    "Lastly, to create an interaction profile database we first create fingerprints the size of our number of drugs and then transform them into RDkit fingerprints. Afterwards, we use the Tanimoto Coefficient to calculate the similarity between the interaction profiles between two drugs.\n",
    "\n",
    "All these fingerprints as well as the three final databases will be stored for quick check-ups during later calculations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating drug-pair similarity matrices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tables to look up similarity scores for each possible drug combination, it is time to build the drug-pair similarity matrices. The process is the same for all three features.\n",
    "\n",
    "Since the SVM treats pairs of drugs as singular instances, the similarity matrix needs to contain similarity scores between drug-pairs rather than individual drugs as is the case in the previously created databases.\n",
    "\n",
    "To calculate the entries in the similarity matrices for each feature we use the following formula:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S\\big((d_1,d_1') , (d_2,d_2')) = max \\big( s(d_1,d_2) \\cdot s(d_1',d_2') , s(d_2,d_1') \\cdot s(d_1, d_2'))$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The letter $s$ denotes the similarity scores previously calculated and stored in the above-mentioned databases, while $S$ stands for the similarity score of the drug-pairs and will be saved in the new similarity matrix.\n",
    "\n",
    "Although the values $s(d_1,d_1')$ and $s(d_1',d_1)$ are identical, there is a difference between $s(d_1,d_2) \\cdot s(d_1',d_2')$ and $s(d_1',d_2) \\cdot s(d_1,d_2')$. Therefore, we choose the maximum between those two values for $S$ to ensure we store the score for the comparison with maximum similarity between the individual drugs for better accuracy and predictability.\n",
    "\n",
    "Notably, the resulting drug-pair similarity matrices only contains the pair $(d_1,d_1')$ once and no cell or row marked with $(d_1',d_1)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the pairwise kernel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we simply add the scores of all three drug-pair similarity matrices together, giving each feature the same importance. As a result, the values in the final similarity matrix we use as our pairwise kernel function range from 0 to 3 rather than 0 to 1 as in the underlying drug-pair similarity matrices."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling and Evaluating the SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding our labelled training dataset and our new kernel function we create the SVM. Since we use a soft margin classifier, we add an error penalty parameter C with C>0 which is called the soft-margin constant.\n",
    "\n",
    "TODO (Look into how exactly to set up the SVM with all the appropriate parameters)\n",
    "\n",
    "We then use 10-fold cross-validation to evaluate the model, using the area under the receiver operating characteristic curve (AUC) as a criterion due to it being not affected by the ratio of positives to negatives. During each of these rounds we perform one additional 3-fold cross validation to select the best performing value for the error parametre $C$ in the range of {0.1, 1, 10} according to AUC.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical, we will create drug similarity databases for 2D similarity, 3D similarity and interaction profile. Said databases will then be used to create a combined drug-pair similarity matrix shich will serve as the kernel function for a soft-margin-classifier SVM to predict DDI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Sync section titles with TOC</b>: Please make sure that all section titles in the <i>Practical</i> section are synced with the bullet point list provided in the <i>Aim of this talktorial</i> > <i>Contents in Practical</i> section.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "#import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib.lines import Line2D\n",
    "#import matplotlib.patches as mpatches\n",
    "\n",
    "# RDkit imports\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import (\n",
    "    Descriptors,\n",
    "    Draw,\n",
    "    PandasTools,\n",
    "    MACCSkeys,\n",
    "    rdFingerprintGenerator,\n",
    "    AllChem,\n",
    ")\n",
    "# E3FP package imports\n",
    "from e3fp.fingerprint.generate import (\n",
    "    fp,\n",
    "    fprints_dict_from_sdf,\n",
    ")\n",
    "\n",
    "# Scikit-Learn imports\n",
    "from sklearn import (\n",
    "    svm,\n",
    "    datasets,\n",
    "    metrics\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Imports</b>: Please add all your imports on top of this section, ordered by standard library / 3rd party packages / our own (<code>teachopencadd.*</code>). \n",
    "Read more on imports and import order in the <a href=\"https://www.python.org/dev/peps/pep-0008/#imports\">\"PEP 8 -- Style Guide for Python Code\"</a>.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = Path(_dh[-1])\n",
    "DATA = HERE / \"data\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Relative paths</b>: Please define all paths relative to this talktorial's path by using the global variable <code>HERE</code>.\n",
    "If your talktorial has input/output data, please define the global <code>DATA</code>, which points to this talktorial's data folder (check out the default folder structure of each talktorial).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Data from DrugBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Molecules in SMILES format\n",
    "drug_smiles = [\n",
    "    #\"CC1C2C(C3C(C(=O)C(=C(C3(C(=O)C2=C(C4=C1C=CC=C4O)O)O)O)C(=O)N)N(C)C)O\",\n",
    "    \"CC1(C(N2C(S1)C(C2=O)NC(=O)C(C3=CC=C(C=C3)O)N)C(=O)O)C\",\n",
    "    \"C1=COC(=C1)CNC2=CC(=C(C=C2C(=O)O)S(=O)(=O)N)Cl\",\n",
    "    \"C1NC2=CC(=C(C=C2S(=O)(=O)N1)S(=O)(=O)N)Cl\",\n",
    "    \"CC1=C(C(CCC1)(C)C)C=CC(=CC=CC(=CC(=O)O)C)C\",\n",
    "    #\"CC1(C2CC3C(C(=O)C(=C(C3(C(=O)C2=C(C4=C1C=CC=C4O)O)O)O)C(=O)N)N(C)C)O\",\n",
    "]\n",
    "\n",
    "# List of molecule names\n",
    "drug_names = [\n",
    "    #\"Doxycycline\",\n",
    "    \"Amoxicilline\",\n",
    "    \"Furosemide\",\n",
    "    \"Hydrochlorothiazide\",\n",
    "    \"Isotretinoin\",\n",
    "    #\"Tetracycline\",\n",
    "]\n",
    "\n",
    "drug_sdf = [\n",
    "    #\"Doxycycline.sdf\",\n",
    "    \"Amoxicilline.sdf\",\n",
    "    \"Furosemide.sdf\",\n",
    "    \"Hydrochlorothiazide.sdf\",\n",
    "    \"Isotretinoin.sdf\",\n",
    "    #\"Tetracycline.sdf\",\n",
    "]\n",
    "\n",
    "drug_interactions = [\n",
    "    [\"Furosemide\", \"Isotretinoin\"],\n",
    "    [\"Amoxicilline\", \"Isotretinoin\"],\n",
    "    [],\n",
    "    [\"Amoxicilline\"],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data\n",
    "drugs = pd.DataFrame({\n",
    "    \"id\": drug_names, \n",
    "    \"smiles\":drug_smiles, \n",
    "    \"sdf_file\":drug_sdf,\n",
    "    \"ddi\": drug_interactions\n",
    "})\n",
    "\n",
    "# constants used throughout the tutorial\n",
    "num_drugs = drugs[\"id\"].size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a drug-drug 2D molecular structure similarity database using RDkit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary to map the drugs to their SMILES and then create molecules from said SMILES in order to calculate the MACCS fingerprints with the provided function from RDkit. Once we have the fingerprints we create a similarity matrix containing the Tanimoto Scores calculated from the MACCS fingerprints.\n",
    "\n",
    "Since a similarity matrix is always symmetrical, we save calculation time by starting the inner loop at position i. That way we compare a drug only to those following after, since a comparison to the ones before were already done in the previous runs of the loop.\n",
    "\n",
    "For easier access to the scores saved within the similarity matrix, we create a panda DataFrame, naming the columns and rows after our drugs. That way, we can access the scores by using the names of the drugs rather than having to figure out at which specific index said drugs are within the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reate Molecule from SMILE\n",
    "drugs[\"2D_molecule\"] = [Chem.MolFromSmiles(x) for x in drugs[\"smiles\"]]\n",
    "# create MACCS fingerprint\n",
    "drugs[\"maccs\"] = [MACCSkeys.GenMACCSKeys(x) for x in drugs[\"2D_molecule\"]]\n",
    "\n",
    "# calculate Tanimoto Coefficent of MACCS fingerprints\n",
    "scores_2D = np.zeros((num_drugs,num_drugs))\n",
    "for i in range(num_drugs):\n",
    "    for j in range(i, num_drugs):\n",
    "        score = DataStructs.TanimotoSimilarity(drugs[\"maccs\"][i],drugs[\"maccs\"][j])\n",
    "        scores_2D[i][j] = scores_2D[j][i] = score\n",
    "drugs_2D_database = pd.DataFrame(scores_2D, drugs[\"id\"], drugs[\"id\"])\n",
    "#print(drugs_2D_database)\n",
    "#print(drugs_2D_database[\"Amoxicilline\"][\"Furosemide\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a drug-drug 3D pharmacophoric similarity database using the E3FP and RDkit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step we make is creating E3FP fingerprints with the help of the identically named package. This can be done directly from the provided 3D-SDF files with the *fprints_dict_from_sdf* function. This function takes the name of the SDF-file and an additional parametre *first=1* to define that we only want to look at the first conformer within the respective file.\n",
    "\n",
    "After that, we convert the E3FP fingerprint into a fingerprint as recognized by RDkit before calculating and saving the Tanimoto Coefficients in a similarity matrix in the same manner as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 21:05:33,090|INFO|Generating fingerprints for 33613.\n",
      "2023-06-19 21:05:33,222|INFO|Generated 1 fingerprints for 33613.\n",
      "2023-06-19 21:05:33,228|INFO|Generating fingerprints for 3440.\n",
      "2023-06-19 21:05:33,329|INFO|Generated 1 fingerprints for 3440.\n",
      "2023-06-19 21:05:33,332|INFO|Generating fingerprints for 3639.\n",
      "2023-06-19 21:05:33,396|INFO|Generated 1 fingerprints for 3639.\n",
      "2023-06-19 21:05:33,403|INFO|Generating fingerprints for 5282379.\n",
      "2023-06-19 21:05:33,507|INFO|Generated 1 fingerprints for 5282379.\n"
     ]
    }
   ],
   "source": [
    "# create 3D_fingerprints directly from the provided sdf_files\n",
    "fp_dict = [fprints_dict_from_sdf(x,first=1) for x in \"data/\"+drugs[\"sdf_file\"]]\n",
    "\n",
    "# get the fingerprints out of the dictionary\n",
    "fingerprints = [fp[5][0] for fp in fp_dict]\n",
    "\n",
    "# convert e3fp fingerprint object into RDkit fingerprint object\n",
    "drugs[\"e3fp\"] = [fp.fold().to_rdkit() for fp in fingerprints]\n",
    "\n",
    "# calculate Tanimoto coefficient\n",
    "scores_3D = np.zeros((num_drugs,num_drugs))\n",
    "for i in range(num_drugs):\n",
    "    for j in range(i, num_drugs):\n",
    "        score = DataStructs.TanimotoSimilarity(drugs[\"e3fp\"][i],drugs[\"e3fp\"][j])\n",
    "        scores_3D[i][j] = scores_3D[j][i] = score\n",
    "drugs_3D_database = pd.DataFrame(scores_3D, drugs[\"id\"], drugs[\"id\"])\n",
    "#print(drugs_3D_database)\n",
    "#print(drugs_3D_database[\"Amoxicilline\"][\"Furosemide\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a drug-drug interaction profile database using RDkit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike in the above cases, we create the interaction profile fingerprints ourselves here as described in the Theory part. The resulting numpy arrays will then be converted into bitstrings and then fingerprints as recognized by RDkit. Said fingerprints will then be saved for later comparisons.\n",
    "\n",
    "After that, we once again calculate and save the Tanimoto Coefficients in a similarity matrix as a pandas DataFrame with the names of the drugs to specify columns and rows of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                   Amoxicilline  Furosemide  Hydrochlorothiazide   \n",
      "id                                                                   \n",
      "Amoxicilline             1.000000    0.333333                  0.0  \\\n",
      "Furosemide               0.333333    1.000000                  0.0   \n",
      "Hydrochlorothiazide      0.000000    0.000000                  1.0   \n",
      "Isotretinoin             0.000000    0.500000                  0.0   \n",
      "\n",
      "id                   Isotretinoin  \n",
      "id                                 \n",
      "Amoxicilline                  0.0  \n",
      "Furosemide                    0.5  \n",
      "Hydrochlorothiazide           0.0  \n",
      "Isotretinoin                  1.0  \n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Create interaction profile fingerprints\n",
    "fps = []\n",
    "for i in range(num_drugs):\n",
    "    DDI_fp = np.zeros(num_drugs)\n",
    "    for j in range(num_drugs):\n",
    "        if drugs[\"id\"][j] in drugs[\"ddi\"][i]:\n",
    "            DDI_fp[j] = 1\n",
    "    # change array into bitstring\n",
    "    bitstring = \"\".join(DDI_fp.astype(str))\n",
    "    # change bitstring to RDkit fingerprint and add to fingerprints\n",
    "    fps.append(DataStructs.cDataStructs.CreateFromBitString(bitstring))\n",
    "    \n",
    "drugs[\"ipfp\"] = fps\n",
    "\n",
    "# calculate Tanimoto Coefficient\n",
    "scores_IP = np.zeros((num_drugs,num_drugs))\n",
    "for i in range(num_drugs):\n",
    "    for j in range(i, num_drugs):\n",
    "        score = DataStructs.TanimotoSimilarity(drugs[\"ipfp\"][i],drugs[\"ipfp\"][j])\n",
    "        scores_IP[i][j] = scores_IP[j][i] = score\n",
    "drugs_IP_database = pd.DataFrame(scores_IP, drugs[\"id\"], drugs[\"id\"])\n",
    "print(drugs_IP_database)\n",
    "print(drugs_IP_database[\"Amoxicilline\"][\"Furosemide\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a combined pairwise similarity matrix for the kernel function"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create our actual training-data points for the SVM, meaning we create instances of DDI (aka drug-pairs) and label them with 1 for an interaction and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create labelled drug-pair data points\n",
    "drug_pairs_partner = []\n",
    "drug_pairs_names = []\n",
    "drug_pairs_labels = []\n",
    "for i in range(num_drugs):\n",
    "    for j in range(i+1, num_drugs):\n",
    "        drug_pairs_partner.append([drugs[\"id\"][i], drugs[\"id\"][j]])\n",
    "        drug_pairs_names.append(drugs[\"id\"][i] + \" + \" + drugs[\"id\"][j])\n",
    "        if drugs[\"id\"][j] in drugs[\"ddi\"][i] or drugs[\"id\"][i] in drugs[\"ddi\"][j]:\n",
    "            drug_pairs_labels.append(1)\n",
    "        else:\n",
    "            drug_pairs_labels.append(0)\n",
    "\n",
    "print(drug_pairs_partner)\n",
    "print(drug_pairs_names)\n",
    "print(drug_pairs_labels)\n",
    "\n",
    "# create our training dataset for the SVM\n",
    "pairs = pd.DataFrame({\n",
    "    \"partner\" : drug_pairs_partner,\n",
    "    \"id\": drug_pairs_names, \n",
    "    \"label\": drug_pairs_labels, \n",
    "})\n",
    "num_pairs = pairs[\"id\"].size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our drug-pairs as single instances, we have to calculate similarity matrices for 2D, 3D, and interaction profile similarity and save them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairwise similarity matrices\n",
    "pair_scores_2D = np.zeros((num_pairs,num_pairs))\n",
    "pair_scores_3D = np.zeros((num_pairs,num_pairs))\n",
    "pair_scores_IP = np.zeros((num_pairs,num_pairs))\n",
    "for i in range(num_pairs):\n",
    "    for j in range(i, num_pairs):\n",
    "        d1 = pairs[\"partner\"][i]\n",
    "        d2 = pairs[\"partner\"][j]\n",
    "        # calculate 2D pairwise similarity\n",
    "        score1 = np.dot(drugs_2D_database[d1[0]][d2[0]] , drugs_2D_database[d1[1]][d2[1]])\n",
    "        score2 = np.dot(drugs_2D_database[d1[1]][d2[0]] , drugs_2D_database[d1[0]][d2[1]])\n",
    "        pair_scores_2D[i][j] = pair_scores_2D[j][i] = max(score1, score2)\n",
    "        \n",
    "        #calculate 3D pairwise similarity\n",
    "        score1 = np.dot(drugs_3D_database[d1[0]][d2[0]] , drugs_3D_database[d1[1]][d2[1]])\n",
    "        score2 = np.dot(drugs_3D_database[d1[1]][d2[0]] , drugs_3D_database[d1[0]][d2[1]])\n",
    "        pair_scores_3D[i][j] = pair_scores_3D[j][i] = max(score1, score2)\n",
    "\n",
    "        #calculate IP pairwise similarity\n",
    "        score1 = np.dot(drugs_IP_database[d1[0]][d2[0]] , drugs_IP_database[d1[1]][d2[1]])\n",
    "        score2 = np.dot(drugs_IP_database[d1[1]][d2[0]] , drugs_IP_database[d1[0]][d2[1]])\n",
    "        pair_scores_IP[i][j] = pair_scores_IP[j][i] = max(score1, score2)\n",
    "\n",
    "# save pairwise similarity databases for quick checkups\n",
    "pair_2D_database = pd.DataFrame(pair_scores_2D, pairs[\"id\"], pairs[\"id\"])\n",
    "pair_3D_database = pd.DataFrame(pair_scores_3D, pairs[\"id\"], pairs[\"id\"])\n",
    "pair_IP_database = pd.DataFrame(pair_scores_IP, pairs[\"id\"], pairs[\"id\"])\n",
    "#print(pair_IP_database)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to combine these three similarity matrices into one that will be used for the kernel function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.         0.87848297 0.70433821 0.3935743  0.48167239 0.16666578]\n",
      " [0.87848297 3.         0.11111111 0.83130699 0.16666578 0.31500573]\n",
      " [0.70433821 0.11111111 3.         0.04777607 0.83130699 0.3935743 ]\n",
      " [0.3935743  0.83130699 0.04777607 3.         0.12247791 0.70433821]\n",
      " [0.48167239 0.16666578 0.83130699 0.12247791 3.         0.87848297]\n",
      " [0.16666578 0.31500573 0.3935743  0.70433821 0.87848297 3.        ]]\n"
     ]
    }
   ],
   "source": [
    "pairwise_kernel_matrix = pair_2D_database + pair_3D_database + pair_IP_database\n",
    "#print(pairwise_kernel_matrix)\n",
    "kernel = metrics.pairwise.pairwise_kernels(pairwise_kernel_matrix, metric='precomputed')\n",
    "print(kernel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and evaluate the SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to build the Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Amoxicilline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[165], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m classifier \u001b[39m=\u001b[39m svm\u001b[39m.\u001b[39mSVC(kernel\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprecomputed\u001b[39m\u001b[39m'\u001b[39m,C\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(drug_pairs_labels)\n\u001b[1;32m----> 3\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(drug_pairs_partner,drug_pairs_labels)\n",
      "File \u001b[1;32mc:\\Users\\nessi\\anaconda3\\envs\\py310_caddseminar2023\\lib\\site-packages\\sklearn\\svm\\_base.py:192\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    190\u001b[0m     check_consistent_length(X, y)\n\u001b[0;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[0;32m    195\u001b[0m         dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64,\n\u001b[0;32m    196\u001b[0m         order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    197\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    198\u001b[0m         accept_large_sparse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    199\u001b[0m     )\n\u001b[0;32m    201\u001b[0m y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    203\u001b[0m sample_weight \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\n\u001b[0;32m    204\u001b[0m     [] \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64\n\u001b[0;32m    205\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nessi\\anaconda3\\envs\\py310_caddseminar2023\\lib\\site-packages\\sklearn\\base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\nessi\\anaconda3\\envs\\py310_caddseminar2023\\lib\\site-packages\\sklearn\\utils\\validation.py:1106\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1101\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1103\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[1;32m-> 1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1107\u001b[0m     X,\n\u001b[0;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1109\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1110\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1111\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1112\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1113\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1114\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1115\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1116\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1117\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1118\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1120\u001b[0m )\n\u001b[0;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1124\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\nessi\\anaconda3\\envs\\py310_caddseminar2023\\lib\\site-packages\\sklearn\\utils\\validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[0;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nessi\\anaconda3\\envs\\py310_caddseminar2023\\lib\\site-packages\\sklearn\\utils\\_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[0;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[0;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Amoxicilline'"
     ]
    }
   ],
   "source": [
    "classifier = svm.SVC(kernel='precomputed',C=1.0)\n",
    "print(drug_pairs_labels)\n",
    "classifier.fit(drug_pairs_partner,drug_pairs_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "Wrap up the talktorial's content here and discuss pros/cons and open questions/challenges."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "Ask three questions that the user should be able to answer after doing this talktorial. Choose important take-aways from this talktorial for your questions.\n",
    "\n",
    "1. Question\n",
    "2. Question\n",
    "3. Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<b>Useful checks at the end</b>: \n",
    "    \n",
    "<ul>\n",
    "<li>Clear output and rerun your complete notebook. Does it finish without errors?</li>\n",
    "<li>Check if your talktorial's runtime is as excepted. If not, try to find out which step(s) take unexpectedly long.</li>\n",
    "<li>Flag code cells with <code># TODO: CI</code> that have deterministic output and should be tested within our Continuous Integration (CI) framework.</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
